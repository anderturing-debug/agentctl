# agentctl ðŸ¤–

A lightweight CLI for managing, monitoring, and debugging AI agents across providers.

Think `kubectl` but for AI agents.

```bash
pip install agentctl
```

## Why?

You're running 5 different agents across OpenAI, Anthropic, and local models. Each has its own API, its own logging format, its own way of doing things. You spend more time switching tabs than building.

`agentctl` gives you one interface to rule them all.

## Features

- **Unified agent management** â€” Start, stop, monitor agents across providers
- **Real-time streaming logs** â€” `agentctl logs my-agent --follow`
- **Session management** â€” Save, restore, and fork agent conversations
- **Cost tracking** â€” Know exactly what each agent run costs you
- **Local-first** â€” Everything stored locally. No cloud. No telemetry.
- **Plugin system** â€” Add your own providers in <50 lines

## Quick Start

```bash
# Configure a provider
agentctl config set openai --api-key sk-...
agentctl config set anthropic --api-key sk-ant-...
agentctl config set ollama --endpoint http://localhost:11434

# List available models
agentctl models

# Start a conversation
agentctl run claude-sonnet "Explain transformers in 3 sentences"

# Start an interactive session
agentctl session new --model gpt-4o --name research-agent

# Stream logs from a running session
agentctl logs research-agent --follow

# Check costs
agentctl costs --today
agentctl costs --this-month --by-model

# Save and restore sessions
agentctl session save research-agent
agentctl session list
agentctl session restore research-agent-2024-02-15

# Fork a conversation (branch from a point)
agentctl session fork research-agent --from-message 5

# Compare model outputs
agentctl compare "What causes inflation?" --models claude-sonnet,gpt-4o,llama3.1
```

## Providers

| Provider | Status | Local? |
|----------|--------|--------|
| OpenAI | âœ… | No |
| Anthropic | âœ… | No |
| Ollama | âœ… | Yes |
| LM Studio | âœ… | Yes |
| Groq | âœ… | No |
| Google Gemini | ðŸš§ | No |
| Mistral | ðŸš§ | No |

## Architecture

```
~/.agentctl/
â”œâ”€â”€ config.yaml          # Provider configs & API keys
â”œâ”€â”€ sessions/            # Saved conversation sessions
â”‚   â”œâ”€â”€ research-agent/
â”‚   â”‚   â”œâ”€â”€ session.json
â”‚   â”‚   â””â”€â”€ messages.jsonl
â”œâ”€â”€ costs/               # Cost tracking data
â”‚   â””â”€â”€ 2024-02.json
â””â”€â”€ plugins/             # Custom provider plugins
    â””â”€â”€ my-provider.py
```

## Plugin System

Add a custom provider in <50 lines:

```python
# ~/.agentctl/plugins/my-provider.py
from agentctl.providers import BaseProvider, Message, Response

class MyProvider(BaseProvider):
    name = "my-llm"
    
    def complete(self, messages: list[Message], **kwargs) -> Response:
        # Your implementation here
        ...
    
    def stream(self, messages: list[Message], **kwargs):
        # Yield chunks for streaming
        ...
    
    def list_models(self) -> list[str]:
        return ["my-model-v1", "my-model-v2"]
```

## Cost Tracking

Every API call is tracked locally. No data leaves your machine.

```bash
$ agentctl costs --this-month --by-model
Model                  Calls    Tokens (in/out)    Cost
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
claude-sonnet          142      485K / 89K         $4.21
gpt-4o                 87       312K / 67K         $3.88
llama3.1:8b            203      890K / 156K        $0.00
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total                  432      1.69M / 312K       $8.09
```

## Configuration

```yaml
# ~/.agentctl/config.yaml
providers:
  openai:
    api_key: sk-...
    default_model: gpt-4o
  anthropic:
    api_key: sk-ant-...
    default_model: claude-sonnet
  ollama:
    endpoint: http://localhost:11434
    default_model: llama3.1:8b

defaults:
  provider: anthropic
  temperature: 0.7
  max_tokens: 4096

costs:
  track: true
  alert_threshold: 50.00  # Alert when monthly spend exceeds this
```

## Development

```bash
git clone https://github.com/anderturing-debug/agentctl.git
cd agentctl
pip install -e ".[dev]"
pytest
```

## Roadmap

- [ ] Agent chaining (pipe output of one agent to another)
- [ ] Scheduled agent runs (cron-like)
- [ ] Web UI dashboard (optional)
- [ ] MCP protocol support
- [ ] Multi-agent orchestration
- [ ] Token budget limits per session

## License

MIT

---

Built by [Ander Turing](https://twitter.com/AnderTurin62549) â€” because managing AI agents shouldn't require a PhD in YAML.
